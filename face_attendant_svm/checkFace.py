import os
import cv2
import time
import sqlite3
import numpy as np
import joblib
import subprocess
import platform
from datetime import datetime

try:
    import face_recognition
except Exception as e:
            # X·ª≠ l√Ω face detection m·ªói N frames
            if frame_count % PROCESS_EVERY_N_FRAMES == 0: # type: ignore
                # Resize ƒë·ªÉ tƒÉng t·ªëc ƒë·ªô nh∆∞ng v·∫´n gi·ªØ ch·∫•t l∆∞·ª£ng
                small = cv2.resize(frame, (0, 0), fx=RESIZE_FACTOR, fy=RESIZE_FACTOR) # pyright: ignore[reportUndefinedVariable]
                
                # Face detection v·ªõi mask support
                face_locations, enhanced_small = detect_faces_with_mask_support(small) # pyright: ignore[reportUndefinedVariable]
                
                # Scale back to original size
                scale_factor = 1.0 / RESIZE_FACTOR # pyright: ignore[reportUndefinedVariable]
                boxes = []
                for (t, r, b, l) in face_locations:
                    boxes.append((
                        int(t * scale_factor),
                        int(r * scale_factor),
                        int(b * scale_factor),
                        int(l * scale_factor)
                    ))or(f"Thi·∫øu th∆∞ vi·ªán 'face_recognition': {e}")

# C·∫•u h√¨nh
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
MODELS_DIR = os.path.join(BASE_DIR, "models")
DB_PATH = os.path.join(BASE_DIR, "students.db")
TABLE_NAME = "Student"

SVM_PATH = os.path.join(MODELS_DIR, "svm_model.pkl")
SCALER_PATH = os.path.join(MODELS_DIR, "normalizer.pkl")
SIMPLE_PATH = os.path.join(MODELS_DIR, "simple_model.pkl")
METADATA_PATH = os.path.join(MODELS_DIR, "model_metadata.pkl")

_model_cache = None
_scaler_cache = None
_metadata_cache = None
_last_load_time = 0
CACHE_TIMEOUT = 300

# Th√¥ng s·ªë t·ªëi ∆∞u cho nh·∫≠n di·ªán v·ªõi kh·∫©u trang - AN TO√ÄN
THRESHOLD = 0.55  # TƒÉng threshold ƒë·ªÉ tr√°nh nh·∫≠n nh·∫ßm ng∆∞·ªùi (QUAN TR·ªåNG!)
MIN_CONFIDENCE_GAP = 0.15  # Ch√™nh l·ªách t·ªëi thi·ªÉu gi·ªØa top-1 v√† top-2 (15%)
PROCESS_EVERY_N_FRAMES = 2  # X·ª≠ l√Ω nhi·ªÅu frame h∆°n ƒë·ªÉ ch√≠nh x√°c h∆°n
RESIZE_FACTOR = 0.4  # TƒÉng ƒë·ªô ph√¢n gi·∫£i ƒë·ªÉ nh·∫≠n di·ªán t·ªët h∆°n
TARGET_FPS = 15  # Gi·∫£m FPS ƒë·ªÉ ·ªïn ƒë·ªãnh

# C·∫•u h√¨nh camera
CAMERA_WIDTH = 640  # TƒÉng ch·∫•t l∆∞·ª£ng camera
CAMERA_HEIGHT = 480
FACE_DETECTION_SCALE = 1.1  # Gi·∫£m scale ƒë·ªÉ detect ch√≠nh x√°c h∆°n
MIN_NEIGHBORS = 3  # Gi·∫£m ƒë·ªÉ detect nh·∫°y h∆°n v·ªõi kh·∫©u trang

def speak(text):
    """Cross-platform text-to-speech - H·ªó tr·ª£ c·∫£ macOS v√† Windows"""
    try:
        system = platform.system()
        if system == 'Darwin':  # macOS
            subprocess.Popen(['say', '-v', 'Samantha', text],
                        stdout=subprocess.DEVNULL,
                        stderr=subprocess.DEVNULL)
        elif system == 'Windows':  # Windows
            # S·ª≠ d·ª•ng PowerShell v·ªõi gi·ªçng n·ªØ Zira (Windows 10/11)
            ps_command = f'''
            Add-Type -AssemblyName System.Speech
            $synth = New-Object System.Speech.Synthesis.SpeechSynthesizer
            $synth.SelectVoiceByHints([System.Speech.Synthesis.VoiceGender]::Female)
            $synth.Speak("{text}")
            '''
            subprocess.Popen(['powershell', '-Command', ps_command],
                        stdout=subprocess.DEVNULL,
                        stderr=subprocess.DEVNULL,
                        creationflags=subprocess.CREATE_NO_WINDOW if hasattr(subprocess, 'CREATE_NO_WINDOW') else 0)
        # Linux: C√≥ th·ªÉ th√™m espeak ho·∫∑c festival n·∫øu c·∫ßn
    except Exception:
        # Silent fail - kh√¥ng l√†m g√¨ n·∫øu TTS kh√¥ng kh·∫£ d·ª•ng
        pass

def enhance_image_quality(frame):
    """C·∫£i thi·ªán ch·∫•t l∆∞·ª£ng ·∫£nh - t·ªëi ∆∞u cho nh·∫≠n di·ªán v·ªõi kh·∫©u trang"""
    # TƒÉng ƒë·ªô t∆∞∆°ng ph·∫£n ƒë·ªÉ n·ªïi b·∫≠t v√πng m·∫Øt v√† tr√°n
    lab = cv2.cvtColor(frame, cv2.COLOR_BGR2LAB)
    l, a, b = cv2.split(lab)
    
    # CLAHE ƒë·ªÉ c·∫£i thi·ªán ƒë·ªô t∆∞∆°ng ph·∫£n c·ª•c b·ªô (quan tr·ªçng cho v√πng m·∫Øt)
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
    l = clahe.apply(l)
    
    enhanced = cv2.merge([l, a, b])
    enhanced = cv2.cvtColor(enhanced, cv2.COLOR_LAB2BGR)
    
    # TƒÉng ƒë·ªô s·∫Øc n√©t
    kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]])
    enhanced = cv2.filter2D(enhanced, -1, kernel)
    
    return enhanced

def detect_faces_with_mask_support(frame):
    """Face detection ƒë∆∞·ª£c t·ªëi ∆∞u cho nh·∫≠n di·ªán v·ªõi kh·∫©u trang"""
    # C·∫£i thi·ªán ch·∫•t l∆∞·ª£ng ·∫£nh ƒë·ªÉ detect t·ªët h∆°n v√πng m·∫Øt
    enhanced_frame = enhance_image_quality(frame)
    rgb_frame = cv2.cvtColor(enhanced_frame, cv2.COLOR_BGR2RGB)
    
    # S·ª≠ d·ª•ng CNN model cho ƒë·ªô ch√≠nh x√°c cao h∆°n v·ªõi kh·∫©u trang
    try:
        # CNN t·ªët h∆°n HOG khi nh·∫≠n di·ªán khu√¥n m·∫∑t ƒëeo kh·∫©u trang
        face_locations = face_recognition.face_locations(rgb_frame, model="cnn", number_of_times_to_upsample=1)
        
        # N·∫øu kh√¥ng detect ƒë∆∞·ª£c, th·ª≠ HOG
        if not face_locations:
            face_locations = face_recognition.face_locations(rgb_frame, model="hog")
    except:
        # Fallback v·ªÅ Haar cascade n·∫øu c·∫ßn
        gray = cv2.cvtColor(enhanced_frame, cv2.COLOR_BGR2GRAY)
        face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
        faces = face_cascade.detectMultiScale(gray, FACE_DETECTION_SCALE, MIN_NEIGHBORS)
        face_locations = [(y, x+w, y+h, x) for (x, y, w, h) in faces]
    
    return face_locations, enhanced_frame
    
def extract_face_encodings_with_mask_support(frame, boxes):
    """Extract face encodings ƒë∆∞·ª£c t·ªëi ∆∞u cho nh·∫≠n di·ªán v·ªõi kh·∫©u trang"""
    if not boxes:
        return []
    
    # Enhance image ƒë·ªÉ encoding ch√≠nh x√°c h∆°n
    enhanced_frame = enhance_image_quality(frame)
    rgb_frame = cv2.cvtColor(enhanced_frame, cv2.COLOR_BGR2RGB)
    
    encodings = []
    for box in boxes:
        try:
            # TƒÉng num_jitters ƒë·ªÉ encoding ch√≠nh x√°c h∆°n v·ªõi kh·∫©u trang
            # D√πng model l·ªõn ƒë·ªÉ extract features t·ªët h∆°n t·ª´ v√πng m·∫Øt
            encoding = face_recognition.face_encodings(
                rgb_frame,
                [box],
                num_jitters=5,  # TƒÉng l√™n 5 ƒë·ªÉ ch√≠nh x√°c h∆°n
                model="large"   # D√πng model l·ªõn cho ƒë·ªô ch√≠nh x√°c
            )
            if encoding:
                encodings.extend(encoding)
        except Exception as e:
            print(f" L·ªói encoding: {e}")
            continue
    
    return encodings

def init_attendance_table():
    """Kh·ªüi t·∫°o b·∫£ng ƒëi·ªÉm danh"""
    conn = sqlite3.connect(DB_PATH)
    try:
        cur = conn.cursor()
        cur.execute('''
            CREATE TABLE IF NOT EXISTS attendance (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                student_id TEXT NOT NULL,
                student_name TEXT NOT NULL,
                session TEXT NOT NULL,
                timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
                confidence REAL,
                FOREIGN KEY (student_id) REFERENCES Student (id)
            )
        ''')
        conn.commit()
    finally:
        conn.close()

def record_attendance(student_id: str, student_name: str, confidence: float):
    """Ghi nh·∫≠n ƒëi·ªÉm danh - ch·ªâ 1 l·∫ßn m·ªói ca"""
    now = datetime.now()
    date_str = now.strftime("%Y-%m-%d")
    
    # X√°c ƒë·ªãnh ca h·ªçc
    hour = now.hour
    if hour < 12:
        session = "s√°ng"
    elif hour < 17:
        session = "chi·ªÅu"
    else:
        session = "t·ªëi"
    
    conn = sqlite3.connect(DB_PATH)
    try:
        cur = conn.cursor()
        
        # Ki·ªÉm tra ƒë√£ ƒëi·ªÉm danh ca n√†y h√¥m nay ch∆∞a
        cur.execute('''
            SELECT id FROM attendance
            WHERE student_id = ? AND timestamp LIKE ? AND session = ?
        ''', (student_id, f"{date_str}%", session))
        
        existing_record = cur.fetchone()
        
        if existing_record:
            return False, f"Already attended this session"
        
        # Ghi nh·∫≠n ƒëi·ªÉm danh m·ªõi
        timestamp = now.strftime("%Y-%m-%d %H:%M:%S")
        cur.execute('''
            INSERT INTO attendance
            (student_id, student_name, session, timestamp, confidence)
            VALUES (?, ?, ?, ?, ?)
        ''', (student_id, student_name, session, timestamp, confidence))
        
        conn.commit()
        return True, f"Attendance recorded for {session} session"
        
    finally:
        conn.close()

def get_today_attendance():
    """L·∫•y danh s√°ch ƒëi·ªÉm danh ng√†y h√¥m nay"""
    today = datetime.now().strftime("%Y-%m-%d")
    conn = sqlite3.connect(DB_PATH)
    try:
        cur = conn.cursor()
        cur.execute('''
            SELECT student_name, session, datetime(timestamp) as time
            FROM attendance
            WHERE date(timestamp) = ?
            ORDER BY timestamp DESC
        ''', (today,))
        
        results = []
        for row in cur.fetchall():
            results.append({
                'name': row[0],
                'session': row[1],
                'time': row[2]
            })
        return results
    finally:
        conn.close()

def get_profile(student_id: str):
    """L·∫•y th√¥ng tin sinh vi√™n t·ª´ database"""
    conn = sqlite3.connect(DB_PATH)
    try:
        cur = conn.cursor()
        cur.execute(f"SELECT id, name FROM {TABLE_NAME} WHERE id = ?", (student_id,))
        row = cur.fetchone()
        return {"id": row[0], "name": row[1]} if row else None
    finally:
        conn.close()

def load_model():
    global _model_cache, _scaler_cache, _metadata_cache, _last_load_time
    
    current_time = time.time()
    if _model_cache is not None and (current_time - _last_load_time) < CACHE_TIMEOUT:
        return _model_cache, _scaler_cache, _metadata_cache.get('model_type', 'svm')
    
    if os.path.exists(SVM_PATH) and os.path.exists(SCALER_PATH):
        _model_cache = joblib.load(SVM_PATH)
        _scaler_cache = joblib.load(SCALER_PATH)
        
        if os.path.exists(METADATA_PATH):
            _metadata_cache = joblib.load(METADATA_PATH)
            model_type = _metadata_cache.get('model_type', 'svm_linear')
            print(f" S·ª≠ d·ª•ng {model_type} model")
        else:
            _metadata_cache = {'model_type': 'svm_linear'}
            model_type = 'svm_linear'
            print("S·ª≠ d·ª•ng SVM model")
        
        _last_load_time = current_time
        return _model_cache, _scaler_cache, model_type
        
    elif os.path.exists(SIMPLE_PATH):
        print(" S·ª≠ d·ª•ng Simple Matching model")
        _model_cache = joblib.load(SIMPLE_PATH)
        _scaler_cache = None
        _metadata_cache = {'model_type': 'simple'}
        _last_load_time = current_time
        return _model_cache, None, 'simple'
    else:
        raise FileNotFoundError("Ch∆∞a c√≥ model. Vui l√≤ng hu·∫•n luy·ªán tr∆∞·ªõc!")

def predict_identity(encodings, model, scaler, model_type):
    if model_type in ['svm_linear', 'svm_rbf', 'svm']:
        Xn = scaler.transform(encodings)
        probs = model.predict_proba(Xn)
        classes = model.classes_
        
        results = []
        for prob_row in probs:
            # L·∫•y top-2 predictions ƒë·ªÉ ki·ªÉm tra ƒë·ªô ch√™nh l·ªách
            sorted_indices = np.argsort(prob_row)[::-1]  # S·∫Øp x·∫øp gi·∫£m d·∫ßn
            best_idx = sorted_indices[0]
            best_prob = prob_row[best_idx]
            best_class = classes[best_idx]
            
            # T√≠nh ƒë·ªô ch√™nh l·ªách v·ªõi top-2 (n·∫øu c√≥)
            confidence_gap = 0.0
            if len(sorted_indices) > 1:
                second_idx = sorted_indices[1]
                second_prob = prob_row[second_idx]
                confidence_gap = best_prob - second_prob
            
            results.append((best_class, best_prob, confidence_gap))
        return results
    
    elif model_type == 'knn':
        Xn = scaler.transform(encodings)
        probs = model.predict_proba(Xn)
        classes = model.classes_
        
        results = []
        for prob_row in probs:
            # L·∫•y top-2 predictions ƒë·ªÉ ki·ªÉm tra ƒë·ªô ch√™nh l·ªách
            sorted_indices = np.argsort(prob_row)[::-1]  # S·∫Øp x·∫øp gi·∫£m d·∫ßn
            best_idx = sorted_indices[0]
            best_prob = prob_row[best_idx]
            best_class = classes[best_idx]
            
            # T√≠nh ƒë·ªô ch√™nh l·ªách v·ªõi top-2 (n·∫øu c√≥)
            confidence_gap = 0.0
            if len(sorted_indices) > 1:
                second_idx = sorted_indices[1]
                second_prob = prob_row[second_idx]
                confidence_gap = best_prob - second_prob
            
            results.append((best_class, best_prob, confidence_gap))
        return results
    
    else:
        ref_embedding = model['reference_embedding']
        student_id = model['student_id']
        threshold = model['threshold']
        
        results = []
        for encoding in encodings:
            similarity = np.dot(encoding, ref_embedding) / (
                np.linalg.norm(encoding) * np.linalg.norm(ref_embedding)
            )
            
            # Simple model kh√¥ng c√≥ confidence gap
            confidence_gap = 0.0
            
            if similarity > threshold:
                results.append((student_id, similarity, confidence_gap))
            else:
                results.append(("unknown", similarity, confidence_gap))
        
        return results

def draw_label(frame, text, pos, color=(0, 255, 0)):
    """V·∫Ω label v·ªõi background v√† outline t·ªët h∆°n"""
    x, y = pos
    font = cv2.FONT_HERSHEY_DUPLEX  # Font ƒë·∫πp h∆°n SIMPLEX
    font_scale = 0.6
    thickness = 1
    
    (text_width, text_height), baseline = cv2.getTextSize(text, font, font_scale, thickness)
    
    # Background v·ªõi padding
    padding = 5
    cv2.rectangle(frame, (x-padding, y - text_height - padding*2),
                (x + text_width + padding, y + padding), color, -1)
    
    # Text outline (black border)
    cv2.putText(frame, text, (x, y - 5), font, font_scale, (0, 0, 0), thickness + 1)
    # Text ch√≠nh (white)
    cv2.putText(frame, text, (x, y - 5), font, font_scale, (255, 255, 255), thickness)

def init_camera():
    """Kh·ªüi t·∫°o camera ch·∫•t l∆∞·ª£ng cao cho detection v·ªõi kh·∫©u trang"""
    cap = cv2.VideoCapture(0, cv2.CAP_ANY)
    if not cap.isOpened():
        raise RuntimeError("Kh√¥ng th·ªÉ m·ªü camera!")
    
    # Thi·∫øt l·∫≠p ch·∫•t l∆∞·ª£ng cao
    cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, CAMERA_WIDTH)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, CAMERA_HEIGHT)
    cap.set(cv2.CAP_PROP_FPS, TARGET_FPS)
    
    # T·ªëi ∆∞u cho lighting conditions
    cap.set(cv2.CAP_PROP_AUTO_EXPOSURE, 0.25)  # Gi·∫£m auto exposure
    cap.set(cv2.CAP_PROP_BRIGHTNESS, 0.1)     # TƒÉng brightness nh·∫π
    cap.set(cv2.CAP_PROP_CONTRAST, 0.2)       # TƒÉng contrast
    
    print(f"Camera setup: {CAMERA_WIDTH}x{CAMERA_HEIGHT} @ {TARGET_FPS}FPS")
    time.sleep(1)  # Ch·ªù camera ·ªïn ƒë·ªãnh
    return cap

def main():
    print(" Kh·ªüi ƒë·ªông h·ªá th·ªëng nh·∫≠n di·ªán khu√¥n m·∫∑t - H·ªñ TR·ª¢ KH·∫®U TRANG")
    print("=" * 60)
    
    # Kh·ªüi t·∫°o b·∫£ng ƒëi·ªÉm danh
    init_attendance_table()
    
    # Load model
    model, scaler, model_type = load_model()
    
    # Kh·ªüi t·∫°o camera
    cap = init_camera()
    
    print(f"\n Model: {model_type.upper()}")
    print(f" Threshold: {THRESHOLD} (AN TO√ÄN - tr√°nh nh·∫≠n nh·∫ßm)")
    print(f" Min Confidence Gap: {MIN_CONFIDENCE_GAP} (ch√™nh l·ªách t·ªëi thi·ªÉu)")
    print(f" CNN Detection + CLAHE Enhancement")
    print(f" High-quality encoding (5 jitters)")
    print("\n H∆∞·ªõng d·∫´n:")
    print("  - Nh√¨n th·∫≥ng v√†o camera")
    print("  - ƒêeo kh·∫©u trang KH√îNG che m·∫Øt")
    print("  - Gi·ªØ kho·∫£ng c√°ch 30-50cm t·ª´ camera")
    print("  - √Ånh s√°ng ƒë·ªß (kh√¥ng qu√° t·ªëi)")
    print("\nPress 'q' to quit, 'a' to view attendance list\n")
    
    # Bi·∫øn tr·∫°ng th√°i
    frame_count = 0
    prev_time = time.time()
    fps = 0.0
    
    # Bi·∫øn ƒëi·ªÉm danh
    attendance_messages = []   # L∆∞u th√¥ng b√°o ƒëi·ªÉm danh
    message_display_time = 3   # Gi√¢y hi·ªÉn th·ªã th√¥ng b√°o
    already_notified = set()   # Tr√°nh spam th√¥ng b√°o "ƒë√£ ƒëi·ªÉm danh"
    
    # Cache k·∫øt qu·∫£ ƒë·ªÉ t√°i s·ª≠ d·ª•ng
    cached_boxes = []
    cached_names = []
    
    try:
        while True:
            ret, frame = cap.read()
            if not ret or frame is None:
                print("Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c frame!")
                break
            
            frame_count += 1
            
            # T√≠nh FPS
            now = time.time()
            dt = now - prev_time
            prev_time = now
            fps = 0.9 * fps + 0.1 * (1.0 / dt if dt > 0 else 0.0)
            
            # Ch·ªâ x·ª≠ l√Ω face detection ƒë·ªãnh k·ª≥
            if frame_count % PROCESS_EVERY_N_FRAMES == 0:
                # Resize ƒë·ªÉ tƒÉng t·ªëc ƒë·ªô nh∆∞ng v·∫´n gi·ªØ ch·∫•t l∆∞·ª£ng
                small = cv2.resize(frame, (0, 0), fx=RESIZE_FACTOR, fy=RESIZE_FACTOR)
                
                # Face detection v·ªõi mask support
                face_locations, enhanced_small = detect_faces_with_mask_support(small)
                
                # Scale back to original size
                scale_factor = 1.0 / RESIZE_FACTOR
                boxes = []
                for (t, r, b, l) in face_locations:
                    boxes.append((
                        int(t * scale_factor),
                        int(r * scale_factor),
                        int(b * scale_factor),
                        int(l * scale_factor)
                    ))
                
                names = []
                if boxes:
                    try:
                        # Get face encodings v·ªõi mask support
                        encodings = extract_face_encodings_with_mask_support(frame, boxes)
                        
                        if encodings:
                            # Predict
                            results = predict_identity(
                                np.vstack(encodings), model, scaler, model_type
                            )
                            
                            for label, score, confidence_gap in results:
                                if model_type in ['svm', 'svm_linear', 'svm_rbf', 'knn']:
                                    # Ki·ªÉm tra c·∫£ threshold V√Ä confidence gap ƒë·ªÉ tr√°nh nh·∫≠n nh·∫ßm
                                    is_confident = (score >= THRESHOLD) and (confidence_gap >= MIN_CONFIDENCE_GAP)
                                    score_text = f"{score*100:.1f}%"
                                    gap_text = f"(gap:{confidence_gap*100:.1f}%)"
                                    
                                    # C·∫£nh b√°o n·∫øu confidence gap th·∫•p
                                    if score >= THRESHOLD and confidence_gap < MIN_CONFIDENCE_GAP:
                                        print(f"\n  C·∫¢NH B√ÅO: ƒê·ªô tin c·∫≠y {score_text} ƒë·ªß cao nh∆∞ng gap {gap_text} qu√° th·∫•p!")
                                        print(f"   ‚Üí C√≥ th·ªÉ nh·∫ßm l·∫´n gi·ªØa nhi·ªÅu ng∆∞·ªùi. Y√™u c·∫ßu nh√¨n r√µ h∆°n!\n")
                                else:
                                    is_confident = label != "unknown"
                                    score_text = f"{score:.3f}"
                                    gap_text = ""
                                
                                if is_confident:
                                    profile = get_profile(str(label))
                                    if profile:
                                        student_id = profile['id']
                                        student_name = profile['name']
                                        # Hi·ªÉn th·ªã c·∫£ gap n·∫øu c√≥
                                        display_text = f" {student_name} ({score_text})"
                                        if gap_text:
                                            display_text += f" {gap_text}"
                                        names.append(display_text)
                                        
                                        # X·ª≠ l√Ω ƒëi·ªÉm danh v·ªõi logic th√¥ng minh
                                        success, message = record_attendance(student_id, student_name, score)
                                        
                                        if success:
                                            # ƒêi·ªÉm danh th√†nh c√¥ng - th√¥ng b√°o xanh
                                            success_msg = f" ƒêI·ªÇM DANH TH√ÄNH C√îNG: {student_name} [{student_id}]"
                                            attendance_messages.append({
                                                'message': success_msg,
                                                'time': time.time(),
                                                'color': (0, 255, 0),  # Xanh l√°
                                                'type': 'success'
                                            })
                                            print(f"\n{'='*60}")
                                            print(f" ƒêI·ªÇM DANH TH√ÄNH C√îNG!")
                                            print(f"  T√™n: {student_name}")
                                            print(f"  ID: {student_id}")
                                            print(f"  Ca: {message.split('for ')[1] if 'for' in message else 'N/A'}")
                                            print(f"  ƒê·ªô tin c·∫≠y: {score_text}")
                                            if gap_text:
                                                print(f"  ƒê·ªô ch√™nh l·ªách: {gap_text}")
                                            print(f"{'='*60}\n")
                                            
                                            # Ph√°t √¢m thanh th√¥ng b√°o (cross-platform)
                                            try:
                                                print('\a')  # Terminal beep
                                                speak('Thank you!')
                                            except Exception:
                                                pass
                                            
                                            # X√≥a kh·ªèi set ƒë√£ th√¥ng b√°o ƒë·ªÉ c√≥ th·ªÉ th√¥ng b√°o l·∫°i ·ªü ca kh√°c
                                            already_notified.discard(student_id)
                                        else:
                                            # ƒê√£ ƒëi·ªÉm danh r·ªìi - ch·ªâ hi·ªÉn th·ªã 1 l·∫ßn ƒë·ªÉ kh√¥ng spam
                                            if student_id not in already_notified:
                                                warning_msg = f" ƒê√É ƒêI·ªÇM DANH: {student_name} [{student_id}]"
                                                attendance_messages.append({
                                                    'message': warning_msg,
                                                    'time': time.time(),
                                                    'color': (0, 165, 255),  # Cam
                                                    'type': 'warning'
                                                })
                                                print(f"\n {student_name} [{student_id}] ƒë√£ ƒëi·ªÉm danh ca n√†y r·ªìi!\n")
                                                
                                                # Ph√°t √¢m thanh th√¥ng b√°o ƒë√£ ƒëi·ªÉm danh (cross-platform)
                                                try:
                                                    speak('You have already attended!')
                                                except Exception:
                                                    pass
                                                
                                                already_notified.add(student_id)
                                    else:
                                        names.append(f" {label} ({score_text}) - Ch∆∞a ƒëƒÉng k√Ω")
                                        # Th√¥ng b√°o ng∆∞·ªùi l·∫°/ch∆∞a ƒëƒÉng k√Ω
                                        unknown_key = f"unknown_{label}"
                                        if unknown_key not in already_notified:
                                            attendance_messages.append({
                                                'message': f" Ph√°t hi·ªán ID kh√¥ng t·ªìn t·∫°i: {label}",
                                                'time': time.time(),
                                                'color': (0, 165, 255),
                                                'type': 'warning'
                                            })
                                            already_notified.add(unknown_key)
                                else:
                                    names.append(f" Unknown ({score_text})")
                                    # Th√¥ng b√°o kh√¥ng nh·∫≠n di·ªán ƒë∆∞·ª£c
                                    if "no_recognition" not in already_notified:
                                        attendance_messages.append({
                                            'message': f" Kh√¥ng nh·∫≠n di·ªán ƒë∆∞·ª£c - ƒê·ªô tin c·∫≠y th·∫•p ({score_text})",
                                            'time': time.time(),
                                            'color': (0, 0, 255),
                                            'type': 'error'
                                        })
                                        already_notified.add("no_recognition")
                                        # Reset sau 2 gi√¢y
                                        import threading
                                        def reset_flag():
                                            time.sleep(2)
                                            already_notified.discard("no_recognition")
                                        threading.Thread(target=reset_flag, daemon=True).start()
                        
                    except Exception as e:
                        print(f"L·ªói x·ª≠ l√Ω: {e}")
                        names = ["Error"] * len(boxes)
                
                # Update cache
                cached_boxes = boxes
                cached_names = names
            
            # V·∫Ω k·∫øt qu·∫£ (s·ª≠ d·ª•ng cache)
            for i, (t, r, b, l) in enumerate(cached_boxes):
                if i < len(cached_names):
                    # M√†u s·∫Øc t√πy theo k·∫øt qu·∫£
                    if "" in cached_names[i]:
                        color = (0, 255, 0)  # Xanh l√° - nh·∫≠n di·ªán th√†nh c√¥ng
                        box_thickness = 3
                    elif "" in cached_names[i]:
                        color = (0, 0, 255)  # ƒê·ªè - kh√¥ng nh·∫≠n di·ªán ƒë∆∞·ª£c
                        box_thickness = 2
                    elif "" in cached_names[i]:
                        color = (0, 165, 255)  # Cam - c·∫£nh b√°o
                        box_thickness = 2
                    else:
                        color = (128, 128, 128)  # X√°m - l·ªói
                        box_thickness = 2
                    
                    cv2.rectangle(frame, (l, t), (r, b), color, box_thickness)
                    draw_label(frame, cached_names[i], (l, t), color=color)
            
            # Hi·ªÉn th·ªã th√¥ng tin h·ªá th·ªëng v·ªõi font t·ªët h∆°n
            font = cv2.FONT_HERSHEY_DUPLEX
            font_scale = 0.5
            thickness = 1
            
            info_y = 25
            # Text v·ªõi outline
            cv2.putText(frame, f"FPS: {fps:.1f}", (10, info_y),
                    font, font_scale, (0, 0, 0), thickness + 1)  # Outline
            cv2.putText(frame, f"FPS: {fps:.1f}", (10, info_y),
                    font, font_scale, (255, 255, 255), thickness)  # Text ch√≠nh
            
            info_y += 22
            cv2.putText(frame, f"Model: {model_type.upper()}", (10, info_y),
                    font, font_scale, (0, 0, 0), thickness + 1)
            cv2.putText(frame, f"Model: {model_type.upper()}", (10, info_y),
                    font, font_scale, (255, 255, 255), thickness)
            
            info_y += 22
            cv2.putText(frame, f"Faces: {len(cached_boxes)}", (10, info_y),
                    font, font_scale, (0, 0, 0), thickness + 1)
            cv2.putText(frame, f"Faces: {len(cached_boxes)}", (10, info_y),
                    font, font_scale, (255, 255, 255), thickness)
            
            info_y += 22
            cv2.putText(frame, f"Threshold: {THRESHOLD}", (10, info_y),
                    font, font_scale, (0, 0, 0), thickness + 1)
            cv2.putText(frame, f"Threshold: {THRESHOLD}", (10, info_y),
                    font, font_scale, (255, 255, 255), thickness)
            
            info_y += 22
            cv2.putText(frame, f"Min Gap: {MIN_CONFIDENCE_GAP}", (10, info_y),
                    font, font_scale, (0, 0, 0), thickness + 1)
            cv2.putText(frame, f"Min Gap: {MIN_CONFIDENCE_GAP}", (10, info_y),
                    font, font_scale, (255, 255, 255), thickness)
            
            # Hi·ªÉn th·ªã ca h·ªçc hi·ªán t·∫°i v·ªõi font ƒë·∫πp
            info_y += 22
            current_hour = datetime.now().hour
            if current_hour < 12:
                session_info = "Session: Morning"
                session_color = (0, 255, 255)  # V√†ng
            elif current_hour < 17:
                session_info = "Session: Afternoon"
                session_color = (0, 165, 255)  # Cam
            else:
                session_info = "Session: Evening"
                session_color = (255, 0, 255)  # T√≠m
                
            cv2.putText(frame, session_info, (10, info_y),
                    font, font_scale, (0, 0, 0), thickness + 1)  # Outline
            cv2.putText(frame, session_info, (10, info_y),
                    font, font_scale, session_color, thickness)  # Text ch√≠nh
            
            # Hi·ªÉn th·ªã status bar ·ªü g√≥c ph·∫£i
            status_x = frame.shape[1] - 320
            status_y = 25
            status_font = cv2.FONT_HERSHEY_DUPLEX
            status_scale = 0.5
            status_thickness = 1
            
            # X√°c ƒë·ªãnh tr·∫°ng th√°i hi·ªán t·∫°i
            if len(cached_boxes) == 0:
                status_text = " ƒêang t√¨m khu√¥n m·∫∑t..."
                status_color = (128, 128, 128)  # X√°m
            elif len([n for n in cached_names if "" in n]) > 0:
                status_text = " Nh·∫≠n di·ªán th√†nh c√¥ng!"
                status_color = (0, 255, 0)  # Xanh
            elif len([n for n in cached_names if "" in n]) > 0:
                status_text = " Kh√¥ng nh·∫≠n di·ªán ƒë∆∞·ª£c"
                status_color = (0, 0, 255)  # ƒê·ªè
            else:
                status_text = " ƒêang x·ª≠ l√Ω..."
                status_color = (0, 165, 255)  # Cam
            
            # V·∫Ω background cho status
            (status_w, status_h), _ = cv2.getTextSize(status_text, status_font, status_scale, status_thickness)
            cv2.rectangle(frame, 
                        (status_x - 10, status_y - status_h - 8),
                        (status_x + status_w + 10, status_y + 8),
                        (0, 0, 0), -1)
            cv2.rectangle(frame, 
                        (status_x - 10, status_y - status_h - 8),
                        (status_x + status_w + 10, status_y + 8),
                        status_color, 2)
            
            # V·∫Ω status text
            cv2.putText(frame, status_text, (status_x, status_y),
                    status_font, status_scale, (0, 0, 0), status_thickness + 1)
            cv2.putText(frame, status_text, (status_x, status_y),
                    status_font, status_scale, status_color, status_thickness)
            
            # Hi·ªÉn th·ªã th√¥ng b√°o ƒëi·ªÉm danh v·ªõi font ƒë·∫πp v√† background
            message_y = info_y + 40
            current_time = time.time()
            for i, msg in enumerate(attendance_messages[:]):
                if current_time - msg['time'] < message_display_time:
                    # T√≠nh k√≠ch th∆∞·ªõc text ƒë·ªÉ v·∫Ω background
                    msg_text = msg['message']
                    msg_font = cv2.FONT_HERSHEY_DUPLEX
                    msg_scale = 0.65
                    msg_thickness = 2
                    (text_width, text_height), baseline = cv2.getTextSize(msg_text, msg_font, msg_scale, msg_thickness)
                    
                    # V·∫Ω background v·ªõi padding
                    padding = 8
                    bg_color = (0, 0, 0)  # ƒêen
                    if msg.get('type') == 'success':
                        bg_color = (0, 100, 0)  # Xanh ƒë·∫≠m
                    elif msg.get('type') == 'warning':
                        bg_color = (0, 80, 130)  # Cam ƒë·∫≠m
                    elif msg.get('type') == 'error':
                        bg_color = (0, 0, 100)  # ƒê·ªè ƒë·∫≠m
                    
                    cv2.rectangle(frame, 
                                (5, message_y - text_height - padding),
                                (15 + text_width + padding, message_y + padding),
                                bg_color, -1)
                    
                    # V·∫Ω border
                    cv2.rectangle(frame, 
                                (5, message_y - text_height - padding),
                                (15 + text_width + padding, message_y + padding),
                                msg['color'], 2)
                    
                    # Message v·ªõi outline
                    cv2.putText(frame, msg_text, (10, message_y),
                            msg_font, msg_scale, (0, 0, 0), msg_thickness + 1)  # Outline
                    cv2.putText(frame, msg_text, (10, message_y),
                            msg_font, msg_scale, msg['color'], msg_thickness)  # Text ch√≠nh
                    message_y += text_height + padding * 2 + 5
                else:
                    attendance_messages.remove(msg)
            
            # V·∫Ω banner h∆∞·ªõng d·∫´n ·ªü d∆∞·ªõi m√†n h√¨nh
            banner_height = 80
            banner_y = frame.shape[0] - banner_height
            
            # Background cho banner
            overlay = frame.copy()
            cv2.rectangle(overlay, (0, banner_y), (frame.shape[1], frame.shape[0]), (20, 20, 20), -1)
            cv2.addWeighted(overlay, 0.7, frame, 0.3, 0, frame)
            
            # Border tr√™n banner
            cv2.line(frame, (0, banner_y), (frame.shape[1], banner_y), (100, 100, 100), 2)
            
            # H∆∞·ªõng d·∫´n v·ªõi icon
            instruction_font = cv2.FONT_HERSHEY_DUPLEX
            instruction_scale = 0.45
            instruction_thickness = 1
            
            inst_y = banner_y + 25
            
            # Line 1: Keyboard shortcuts
            cv2.putText(frame, "  Ph√≠m t·∫Øt:", (15, inst_y),
                    instruction_font, instruction_scale, (0, 0, 0), instruction_thickness + 1)
            cv2.putText(frame, "  Ph√≠m t·∫Øt:", (15, inst_y),
                    instruction_font, instruction_scale, (100, 200, 255), instruction_thickness)
            
            cv2.putText(frame, "'q' = Tho√°t", (150, inst_y),
                    instruction_font, instruction_scale, (0, 0, 0), instruction_thickness + 1)
            cv2.putText(frame, "'q' = Tho√°t", (150, inst_y),
                    instruction_font, instruction_scale, (255, 255, 255), instruction_thickness)
            
            cv2.putText(frame, "'a' = Xem DS ƒëi·ªÉm danh", (280, inst_y),
                    instruction_font, instruction_scale, (0, 0, 0), instruction_thickness + 1)
            cv2.putText(frame, "'a' = Xem DS ƒëi·ªÉm danh", (280, inst_y),
                    instruction_font, instruction_scale, (255, 255, 255), instruction_thickness)
            
            inst_y += 25
            
            # Line 2: Instructions
            cv2.putText(frame, " L∆∞u √Ω:", (15, inst_y),
                    instruction_font, instruction_scale, (0, 0, 0), instruction_thickness + 1)
            cv2.putText(frame, " L∆∞u √Ω:", (15, inst_y),
                    instruction_font, instruction_scale, (100, 255, 100), instruction_thickness)
            
            cv2.putText(frame, "Nh√¨n th·∫≥ng camera", (120, inst_y),
                    instruction_font, instruction_scale, (0, 0, 0), instruction_thickness + 1)
            cv2.putText(frame, "Nh√¨n th·∫≥ng camera", (120, inst_y),
                    instruction_font, instruction_scale, (255, 255, 255), instruction_thickness)
            
            cv2.putText(frame, "| Gi·ªØ kho·∫£ng c√°ch 30-50cm", (300, inst_y),
                    instruction_font, instruction_scale, (0, 0, 0), instruction_thickness + 1)
            cv2.putText(frame, "| Gi·ªØ kho·∫£ng c√°ch 30-50cm", (300, inst_y),
                    instruction_font, instruction_scale, (255, 255, 255), instruction_thickness)
            
            inst_y += 25
            
            # Line 3: Session info
            cv2.putText(frame, " M·ªói ca h·ªçc ch·ªâ ƒëi·ªÉm danh 1 l·∫ßn | H·ªó tr·ª£ nh·∫≠n di·ªán khi ƒëeo kh·∫©u trang", (15, inst_y),
                    instruction_font, instruction_scale, (0, 0, 0), instruction_thickness + 1)
            cv2.putText(frame, " M·ªói ca h·ªçc ch·ªâ ƒëi·ªÉm danh 1 l·∫ßn | H·ªó tr·ª£ nh·∫≠n di·ªán khi ƒëeo kh·∫©u trang", (15, inst_y),
                    instruction_font, instruction_scale, (0, 255, 255), instruction_thickness)
            
            cv2.imshow("Face Recognition Attendance System", frame)
            
            # Ki·ªÉm tra ph√≠m - v·ªõi delay nh·ªè h∆°n ƒë·ªÉ responsive h∆°n
            key = cv2.waitKey(30) & 0xFF
            
            if key == ord('q'):
                print(" ƒêang tho√°t...")
                break
            elif key == ord('a') or key == ord('A'):
                # Hi·ªÉn th·ªã danh s√°ch ƒëi·ªÉm danh h√¥m nay
                print(f"\n Key pressed: {chr(key) if 32 <= key <= 126 else key}")
                today_attendance = get_today_attendance()
                print("\n TODAY'S ATTENDANCE LIST:")
                print("=" * 50)
                if today_attendance:
                    for record in today_attendance:
                        print(f"{record['name']} - {record['session']} ({record['time']})")
                else:
                    print("üìù No attendance recorded today")
                print("=" * 50)
                print("üí° Press Enter to continue...")
                input()  # Pause ƒë·ªÉ ƒë·ªçc k·∫øt qu·∫£
            elif 32 <= key <= 126:  # Debug: in ra t·∫•t c·∫£ ph√≠m ƒë∆∞·ª£c nh·∫•n (ch·ªâ k√Ω t·ª± c√≥ th·ªÉ in)
                print(f"Debug - Ph√≠m ƒë∆∞·ª£c nh·∫•n: {key} (chr: {chr(key)})")
                
    except KeyboardInterrupt:
        print("\nD·ª´ng b·ªüi ng∆∞·ªùi d√πng")
    except Exception as e:
        print(f"L·ªói: {e}")
    finally:
        cap.release()
        cv2.destroyAllWindows()
        print("ƒê√£ tho√°t an to√†n")

if __name__ == "__main__":
    main()